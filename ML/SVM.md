### 1. What is SVM?
  - SVM is a classifier formally defined by a separating hyperplane. An hyperplane is a subspace of one dimension less than
    its ambient space. The dimension of a mathematical space (or object) is informally defined as the minimum number of 
    coordinates (x,y,z axis) needed to specify any point (like each blue and red point) within it while an ambient space 
    is the space surrounding a mathematical object. A mathematical object is an abstract object arising in mathematics An
    abstract object is an object which does not exist at any particular time or place, but rather exists as a type of thing,
    i.e., an idea, or abstraction (wikipedia).
  
### 2. What is Kernel?
   - K(x, y) = <f(x), f(y)>. Here K is the kernel function, x, y are n dimensional inputs. f is a map from n-dimension 
    to m-dimension space. < x,y> denotes the dot product. usually m is much larger than n.
   - Kernel is a way of computing the dot product of two vectors ğ± and ğ² in some (possibly very high dimensional) feature 
     space, which is why kernel functions are sometimes called "generalized dot product". 
     Suppose we have a mapping ğœ‘:â„ğ‘›â†’â„ğ‘š that brings our vectors in â„ğ‘› to some feature space â„ğ‘š. Then 
     the dot product of ğ± and ğ² in this space is ğœ‘(ğ±)ğ‘‡ğœ‘(ğ²). A kernel is a function ğ‘˜ that corresponds to this
     dot product, i.e. ğ‘˜(ğ±,ğ²)=ğœ‘(ğ±)ğ‘‡ğœ‘(ğ²).
### Definition of a kernel function 
  - symmetry: ğ‘˜(ğ‘¥,ğ‘¦)=ğ‘˜(ğ‘¦,ğ‘¥)
  - positive semi-definiteness.
    
  
### 3. Gussian Kernel 
  - Another interesting kernel examples is Gaussian kernel. Given two vectors, the similarity will diminish with
    the radius of ğœ. The distance between two objects is "reweighted" by this radius parameter. 
    
### 4. Conveity 
  - f(a * x1 + (1 - a) * x2) <= a f(x1) + (1-a)f(x2) 
  - if second derivative is greater than 0 
  - Function of d variables 
    - value: number 
    - Derivative: d-dimensional vector 
    - Second derovative d x d matrix 
    - Hessian 
### 5. The Kernelk Trick Significance
    - dot rpoducts are a measure of similarity 
    - Convert to euclidean data from real world objects 
    - As long as the function that we build takes two objects and returns the user defined 
      simliarities. 
### 6. Perceptron adn linear Separability 
    - which perceptron is better when there are multuple percetrons?
    - which perceptron algo return? Find a better generalized data algorithm. 
    - perceptron cannot guarantee the best decision boundry but a legitimate one 
### 
    
